# Machine-Learning-Notes
Draft of Machine Learning Notes for CS5339 Machine Learning at NUS.

## Contents so far
### 1 Formulation
#### 1.1 Supervised Learning
1.1.1 Empirical Risk Minimization (ERM) <br>
1.1.2 Maximum Likelihood Estimation (MLE) <br>
1.1.3 Classification Loss Functions <br>
1.1.4 Maximum A Posteriori Estimation (MAPE) <br>
1.1.5 Bayesian Estimation <br>
#### 1.2 Unsupervised Learning
#### 1.3 Discriminative/Generative Models
1.3.1 Naive Bayes <br>
1.3.2 Linear Discriminant Analysis (LDA) <br>
1.3.3 Discriminative VS Generative Classifiers <br>
#### 1.4 Feature
1.4.1 Filter <br>
1.4.2 Wrapper <br>
1.4.3 Sparsity-Inducing Norms <br>
1.4.4 Common Feature Transformation Methods <br>
1.4.5 Feature Learning <br>
### 2 Representation
#### 2.1 Nearest Neighbor (NN)
#### 2.2 Decision Tree
#### 2.3 Linear Predictors
#### 2.4 Support Vector Machine
2.4.1 Margin and Hard SVM <br>
2.4.2 Representation Power of Linear Threshold Functions <br>
2.4.3 How many functions can a linear threshold function represent? <br>
#### 2.5 Linear combination of Functions
#### 2.6 Kernel Method
2.6.1 Hilbert Space <br>
2.6.2 Representer Theorem <br>
2.6.3 Characterizing Kernel Functions <br>
#### 2.7 Neural Networks
2.7.1 Representing All Boolean Functions <br>
2.7.2 Representing PARITY <br>
2.7.3 Approximating Real-valued Functions <br>
2.7.4 Summary of Representational Properties <br>
2.7.5 Single Hidden Layer NN In Practice <br>
#### 2.8 Matrix/Tensor Factorization
2.8.1 Principal Component Analysis (PCA) <br>
2.8.2 Latent Semantic Analysis (LSA) <br>
2.8.3 Representation as Linear Combination of Functions <br>
2.8.4 Collaborative Filtering <br>
#### 2.9 Ensemble Methods

## Credit
Most of the contents come from lecturer ([Prof Lee Wee Sun](https://www.comp.nus.edu.sg/~leews/))'s slides.
